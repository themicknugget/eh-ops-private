---
apiVersion: v1
kind: ConfigMap
metadata:
  name: localai-config
  namespace: localai
data:
  DEBUG: "false"
  THREADS: "4"
  CONTEXT_SIZE: "4096"
  USE_VULKAN: "true"
  LOCALAI_DISABLE_TELEMETRY: "true"
  CORS: "true"
  CORS_ALLOW_ORIGINS: "*"
  # Install llama-cpp backend on startup
  LOCALAI_PRELOAD_BACKEND: "llama-cpp"
