---
apiVersion: v1
kind: ConfigMap
metadata:
  name: metrics-exporter
  namespace: llama-cpp
  labels:
    app: llama-server
data:
  exporter.py: |
    #!/usr/bin/env python3
    """
    Metrics exporter sidecar for llama-cpp.

    Supports both:
    - Single model mode: scrapes metrics from port 8080 directly
    - Router mode: scrapes metrics from child servers

    Exposes consolidated metrics with model labels on port 9090.
    """

    import http.server
    import json
    import os
    import re
    import socket
    import urllib.request
    import urllib.error
    from typing import Optional

    LLAMA_URL = "http://localhost:8080"
    LISTEN_PORT = 9090
    REQUEST_TIMEOUT = 5

    # Cached mode detection
    _is_router_mode: Optional[bool] = None


    def detect_router_mode() -> bool:
        """Detect if llama-server is running in router mode."""
        global _is_router_mode
        if _is_router_mode is not None:
            return _is_router_mode

        try:
            with urllib.request.urlopen(f"{LLAMA_URL}/v1/models", timeout=REQUEST_TIMEOUT) as resp:
                data = json.loads(resp.read().decode())
                # Router mode returns models with status.args containing child server info
                for model in data.get("data", []):
                    status = model.get("status", {})
                    if "args" in status:
                        _is_router_mode = True
                        print("Detected router mode")
                        return True
        except Exception:
            pass

        _is_router_mode = False
        print("Detected single model mode")
        return False


    def get_model_name_single_mode() -> str:
        """Get model name in single model mode from /v1/models."""
        try:
            with urllib.request.urlopen(f"{LLAMA_URL}/v1/models", timeout=REQUEST_TIMEOUT) as resp:
                data = json.loads(resp.read().decode())
                models = data.get("data", [])
                if models:
                    return models[0].get("id", "unknown")
        except Exception as e:
            print(f"Error getting model name: {e}")
        return os.environ.get("MODEL_NAME", "unknown")


    def get_loaded_models_router() -> list[tuple[str, int]]:
        """
        Query router for loaded models and their ports.
        Returns list of (model_id, port) tuples.
        """
        models = []
        try:
            with urllib.request.urlopen(f"{LLAMA_URL}/v1/models", timeout=REQUEST_TIMEOUT) as resp:
                data = json.loads(resp.read().decode())
        except (urllib.error.URLError, socket.timeout, json.JSONDecodeError) as e:
            print(f"Error fetching models: {e}")
            return models

        for model in data.get("data", []):
            model_id = model.get("id", "")
            status = model.get("status", {})

            if status.get("value") != "loaded":
                continue

            args = status.get("args", [])
            port = None
            for i, arg in enumerate(args):
                if arg == "--port" and i + 1 < len(args):
                    try:
                        port = int(args[i + 1])
                    except ValueError:
                        pass
                    break

            if port:
                models.append((model_id, port))

        return models


    def scrape_metrics(port: int) -> Optional[str]:
        """Scrape metrics from a server."""
        url = f"http://localhost:{port}/metrics"
        try:
            with urllib.request.urlopen(url, timeout=REQUEST_TIMEOUT) as resp:
                return resp.read().decode()
        except (urllib.error.URLError, socket.timeout) as e:
            print(f"Error scraping port {port}: {e}")
            return None


    def add_model_label(metrics: str, model_id: str) -> str:
        """Add model label to each metric line."""
        lines = []
        safe_model_id = model_id.replace("\\", "\\\\").replace('"', '\\"')

        for line in metrics.splitlines():
            if not line or line.startswith("#"):
                lines.append(line)
                continue

            match = re.match(r'^([a-zA-Z_:][a-zA-Z0-9_:]*)\{(.+)\}\s+(.+)$', line)
            if match:
                name, labels, value = match.groups()
                lines.append(f'{name}{{model="{safe_model_id}",{labels}}} {value}')
                continue

            match = re.match(r'^([a-zA-Z_:][a-zA-Z0-9_:]*)\s+(.+)$', line)
            if match:
                name, value = match.groups()
                lines.append(f'{name}{{model="{safe_model_id}"}} {value}')
                continue

            lines.append(line)

        return "\n".join(lines)


    def collect_metrics() -> str:
        """Collect metrics based on mode."""
        output_parts = ["# llama-cpp metrics with model labels", ""]

        if detect_router_mode():
            # Router mode: scrape child servers
            models = get_loaded_models_router()
            if not models:
                output_parts.append("# No loaded models found")
                return "\n".join(output_parts)

            for model_id, port in models:
                output_parts.append(f"# Model: {model_id} (port {port})")
                metrics = scrape_metrics(port)
                if metrics:
                    output_parts.append(add_model_label(metrics, model_id))
                else:
                    output_parts.append(f"# Failed to scrape metrics for {model_id}")
                output_parts.append("")
        else:
            # Single model mode: scrape main server directly
            model_id = get_model_name_single_mode()
            output_parts.append(f"# Model: {model_id}")
            metrics = scrape_metrics(8080)
            if metrics:
                output_parts.append(add_model_label(metrics, model_id))
            else:
                output_parts.append("# Failed to scrape metrics")

        return "\n".join(output_parts)


    class MetricsHandler(http.server.BaseHTTPRequestHandler):
        def do_GET(self):
            if self.path == "/metrics":
                metrics = collect_metrics()
                self.send_response(200)
                self.send_header("Content-Type", "text/plain; charset=utf-8")
                self.end_headers()
                self.wfile.write(metrics.encode())
            elif self.path == "/health":
                self.send_response(200)
                self.send_header("Content-Type", "text/plain")
                self.end_headers()
                self.wfile.write(b"OK")
            else:
                self.send_response(404)
                self.end_headers()

        def log_message(self, format, *args):
            pass


    def main():
        server = http.server.HTTPServer(("0.0.0.0", LISTEN_PORT), MetricsHandler)
        print(f"Metrics exporter listening on port {LISTEN_PORT}")
        server.serve_forever()


    if __name__ == "__main__":
        main()
